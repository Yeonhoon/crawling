{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "source": [
    "import os\r\n",
    "from os import kill\r\n",
    "from selenium import webdriver\r\n",
    "from selenium.webdriver.common.keys import Keys\r\n",
    "from selenium.webdriver.support.ui import WebDriverWait\r\n",
    "from selenium.webdriver.support import expected_conditions as EC\r\n",
    "# from selenium.webdriver.common.by import By\r\n",
    "# from selenium.common.exceptions import NoSuchElementException\r\n",
    "# from selenium.common.exceptions import StaleElementReferenceException\r\n",
    "# from selenium.common.exceptions import ElementNotInteractableException\r\n",
    "# from selenium.common.exceptions import ElementClickInterceptedException\r\n",
    "import time\r\n",
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "\r\n",
    "\r\n",
    "def article_search(key, outfile):\r\n",
    "    driver = webdriver.Chrome(\"C:/chromedriver\")  #브라우저 켜기\r\n",
    "    driver.get('https://pubmed.ncbi.nlm.nih.gov/') \r\n",
    "    toAdvance = driver.find_element_by_css_selector('a.search-input-link')\r\n",
    "    toAdvance.click()\r\n",
    "\r\n",
    "    # title과 abstract으로 설정\r\n",
    "    title_abstrac = driver.find_element_by_css_selector('select#field-selector')\r\n",
    "    title_abstrac.click()\r\n",
    "    opt = driver.find_element_by_css_selector('#field-selector > option:nth-child(39)')\r\n",
    "    opt.click()\r\n",
    "\r\n",
    "    # Input Keywords\r\n",
    "    search = driver.find_element_by_css_selector('input#id_term')\r\n",
    "    search.click()\r\n",
    "    search.send_keys(key)\r\n",
    "    search.send_keys(Keys.ENTER)\r\n",
    "\r\n",
    "    searchBtn = driver.find_element_by_css_selector('#search-form > div > div > div.query-box-section-wrapper > div.button-wrapper > button')\r\n",
    "    searchBtn.click()\r\n",
    "\r\n",
    "    title_arr = []\r\n",
    "    year_arr = []\r\n",
    "    author_arr = []\r\n",
    "    journal_arr = []\r\n",
    "    link_arr = []\r\n",
    "    abstract_arr = []\r\n",
    "\r\n",
    "    titles = driver.find_elements_by_css_selector('a.docsum-title')\r\n",
    "    cnt = 0\r\n",
    "    result = int(driver.find_element_by_css_selector('div.results-amount > span.value').text)\r\n",
    "    for _ in range(result):\r\n",
    "        titles = driver.find_elements_by_css_selector('a.docsum-title')\r\n",
    "        num = driver.find_element_by_css_selector('#search-results > section > div.search-results-chunks > div > article:nth-child(2) > div.item-selector-wrap.selectors-and-actions.first-selector > label > span').text\r\n",
    "        \r\n",
    "        # print(\"lenght: \", len(titles))\r\n",
    "        # print(\"num:\", num)\r\n",
    "        if len(titles) > 10:\r\n",
    "            titles2 = driver.find_elements_by_css_selector('a.docsum-title')\r\n",
    "            titles2[10].click()\r\n",
    "            driver.back()\r\n",
    "        elif len(titles) <= 10:\r\n",
    "            for i in range(len(titles)):\r\n",
    "                time.sleep(1)\r\n",
    "                titles2 = driver.find_elements_by_css_selector('a.docsum-title')\r\n",
    "                titles2[i].click()\r\n",
    "\r\n",
    "                #title\r\n",
    "                title = driver.find_element_by_css_selector('h1.heading-title')\r\n",
    "                title_arr.append(title.text)\r\n",
    "\r\n",
    "                # year\r\n",
    "                try:\r\n",
    "                    year = driver.find_element_by_css_selector('#full-view-heading > div.article-citation > div.article-source > span.cit')\r\n",
    "                    year_arr.append(year.text)\r\n",
    "                except:\r\n",
    "                    year = \"\"\r\n",
    "                    year_arr.append(year)\r\n",
    "\r\n",
    "                #authors\r\n",
    "                try:\r\n",
    "                    authors = driver.find_element_by_css_selector('#full-view-heading > div.inline-authors > div > div > span:nth-child(1) > a')\r\n",
    "                    author_arr.append(authors.text)\r\n",
    "                except:\r\n",
    "                    author = \"\"\r\n",
    "                    author_arr.append(author)\r\n",
    "                # journals\r\n",
    "                try:\r\n",
    "                    journal = driver.find_element_by_css_selector('#full-view-heading > div.article-citation > div > div > button') \r\n",
    "                    journal_arr.append(journal.text)\r\n",
    "                except:\r\n",
    "                    journal = \"\"\r\n",
    "                    journal_arr.append(journal)\r\n",
    "                # abstract\r\n",
    "                try:\r\n",
    "                    abstract = driver.find_element_by_css_selector('div.abstract-content')\r\n",
    "                    abstract_arr.append(abstract.text)\r\n",
    "                except:\r\n",
    "                    abstract = \"\"\r\n",
    "                    abstract_arr.append(abstract)\r\n",
    "\r\n",
    "                #link\r\n",
    "                try:\r\n",
    "                    link = driver.find_elements_by_css_selector('a.id-link')\r\n",
    "                    href= link[-1].get_attribute('href')\r\n",
    "                \r\n",
    "                except IndexError:\r\n",
    "                    href = None\r\n",
    "                link_arr.append(href)\r\n",
    "\r\n",
    "                driver.back()\r\n",
    "                cnt += 1\r\n",
    "                \r\n",
    "                if i == 9:\r\n",
    "                    ## Show More\r\n",
    "                    more = driver.find_element_by_css_selector('#search-results > section > div.search-results-paginator.next-results-paginator.has-nav > button > span')\r\n",
    "                    more.click()\r\n",
    "                    time.sleep(1.2)\r\n",
    "            print(f\"Article Count: {cnt}, Proceeding rate: {round(cnt/int(result) * 100, 2)}%\")\r\n",
    "        if len(title_arr) == result:\r\n",
    "            df = pd.DataFrame(np.c_[title_arr, year_arr, journal_arr, author_arr, link_arr, abstract_arr], columns=['title','year', 'journal','authors','links','abstract'])\r\n",
    "            df.to_csv(outfile, encoding='utf8')\r\n",
    "            print('Done!')\r\n",
    "            break"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "source": [
    "article_search(key=\"(incontinence associated dermatitis[Title/Abstract]) OR diaper dermatitis[Title/Abstract]\",\r\n",
    "outfile='IAD2.csv')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Article Count: 10, Proceeding rate: 1.63%\n",
      "Article Count: 20, Proceeding rate: 3.26%\n",
      "Article Count: 30, Proceeding rate: 4.89%\n",
      "Article Count: 40, Proceeding rate: 6.53%\n",
      "Article Count: 50, Proceeding rate: 8.16%\n",
      "Article Count: 60, Proceeding rate: 9.79%\n",
      "Article Count: 70, Proceeding rate: 11.42%\n",
      "Article Count: 80, Proceeding rate: 13.05%\n",
      "Article Count: 90, Proceeding rate: 14.68%\n",
      "Article Count: 100, Proceeding rate: 16.31%\n",
      "Article Count: 110, Proceeding rate: 17.94%\n",
      "Article Count: 120, Proceeding rate: 19.58%\n",
      "Article Count: 130, Proceeding rate: 21.21%\n",
      "Article Count: 140, Proceeding rate: 22.84%\n",
      "Article Count: 150, Proceeding rate: 24.47%\n",
      "Article Count: 160, Proceeding rate: 26.1%\n",
      "Article Count: 170, Proceeding rate: 27.73%\n",
      "Article Count: 180, Proceeding rate: 29.36%\n",
      "Article Count: 190, Proceeding rate: 31.0%\n",
      "Article Count: 200, Proceeding rate: 32.63%\n",
      "Article Count: 210, Proceeding rate: 34.26%\n",
      "Article Count: 220, Proceeding rate: 35.89%\n",
      "Article Count: 230, Proceeding rate: 37.52%\n",
      "Article Count: 240, Proceeding rate: 39.15%\n",
      "Article Count: 250, Proceeding rate: 40.78%\n",
      "Article Count: 260, Proceeding rate: 42.41%\n",
      "Article Count: 270, Proceeding rate: 44.05%\n",
      "Article Count: 280, Proceeding rate: 45.68%\n",
      "Article Count: 290, Proceeding rate: 47.31%\n",
      "Article Count: 300, Proceeding rate: 48.94%\n",
      "Article Count: 310, Proceeding rate: 50.57%\n",
      "Article Count: 320, Proceeding rate: 52.2%\n",
      "Article Count: 330, Proceeding rate: 53.83%\n",
      "Article Count: 340, Proceeding rate: 55.46%\n",
      "Article Count: 350, Proceeding rate: 57.1%\n",
      "Article Count: 360, Proceeding rate: 58.73%\n",
      "Article Count: 370, Proceeding rate: 60.36%\n",
      "Article Count: 380, Proceeding rate: 61.99%\n",
      "Article Count: 390, Proceeding rate: 63.62%\n",
      "Article Count: 400, Proceeding rate: 65.25%\n",
      "Article Count: 410, Proceeding rate: 66.88%\n",
      "Article Count: 420, Proceeding rate: 68.52%\n",
      "Article Count: 430, Proceeding rate: 70.15%\n",
      "Article Count: 440, Proceeding rate: 71.78%\n",
      "Article Count: 450, Proceeding rate: 73.41%\n",
      "Article Count: 460, Proceeding rate: 75.04%\n",
      "Article Count: 470, Proceeding rate: 76.67%\n",
      "Article Count: 480, Proceeding rate: 78.3%\n",
      "Article Count: 490, Proceeding rate: 79.93%\n",
      "Article Count: 500, Proceeding rate: 81.57%\n",
      "Article Count: 510, Proceeding rate: 83.2%\n",
      "Article Count: 520, Proceeding rate: 84.83%\n",
      "Article Count: 530, Proceeding rate: 86.46%\n",
      "Article Count: 540, Proceeding rate: 88.09%\n",
      "Article Count: 550, Proceeding rate: 89.72%\n",
      "Article Count: 560, Proceeding rate: 91.35%\n",
      "Article Count: 570, Proceeding rate: 92.99%\n",
      "Article Count: 580, Proceeding rate: 94.62%\n",
      "Article Count: 590, Proceeding rate: 96.25%\n",
      "Article Count: 600, Proceeding rate: 97.88%\n",
      "Article Count: 610, Proceeding rate: 99.51%\n",
      "Article Count: 613, Proceeding rate: 100.0%\n",
      "Done!\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "source": [
    "import pandas as pd"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "source": [
    "df=pd.read_csv('IAD2.csv')\r\n",
    "df.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(613, 7)"
      ]
     },
     "metadata": {},
     "execution_count": 53
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "source": [
    "import re\r\n",
    "regex = re.compile(r'\\d{4}')\r\n"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "object of type 'NoneType' has no len()",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-63-3747e7d97efb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mregex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr'\\d{4}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mrst\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mregex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'year'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrst\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "source": [
    "## 연도찾기\r\n",
    "import re\r\n",
    "regex = re.compile(r'\\d{4}')\r\n",
    "result = []\r\n",
    "for i in range(df.shape[0]):\r\n",
    "  temp = str(df['year'][i])\r\n",
    "  rst = regex.findall(temp)\r\n",
    "  if len(rst)>=1:\r\n",
    "    result.append(str(rst[0]))\r\n",
    "  else:\r\n",
    "    result.append(\"\")\r\n",
    "  "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.7.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.10 64-bit ('crawling': conda)"
  },
  "interpreter": {
   "hash": "de560669b33648beb46f12e3cae1035cfbabfbadd5d55af519adf1925ce2b436"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}